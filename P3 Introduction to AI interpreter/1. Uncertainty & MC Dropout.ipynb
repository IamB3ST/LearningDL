{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96fca97f",
   "metadata": {},
   "source": [
    "# Exploring Uncertainty Estimation with Monte Carlo Dropout (MC Dropout)\n",
    "\n",
    "In machine learning, especially in deep learning, it is crucial not only to obtain accurate predictions but also to understand how **confident** a model is in those predictions. This is where **uncertainty estimation** comes in. By quantifying uncertainty, we can make better decisions in high-stakes tasks such as medical diagnosis, autonomous driving, and more.\n",
    "\n",
    "One popular method for estimating uncertainty in neural networks is **Monte Carlo Dropout (MC Dropout)**. In this blog, we will dive into what uncertainty means in the context of deep learning, how MC Dropout helps us estimate uncertainty, and how you can implement it using PyTorch.\n",
    "\n",
    "## What is Uncertainty in Deep Learning?\n",
    "\n",
    "Uncertainty in a machine learning model refers to how confident the model is about its predictions. Generally, there are two types of uncertainty:\n",
    "\n",
    "1. **Aleatoric Uncertainty**: This type of uncertainty arises due to inherent noise or randomness in the data. For example, if the input data is ambiguous or corrupted (e.g., a blurry image), the model's predictions will have high aleatoric uncertainty.\n",
    "  \n",
    "2. **Epistemic Uncertainty**: This type of uncertainty is related to the model itself. It arises due to a lack of knowledge, often caused by insufficient training data. Epistemic uncertainty can be reduced by gathering more data or using a better model.\n",
    "\n",
    "In tasks where wrong predictions could lead to severe consequences (e.g., predicting a disease from medical images), it's important to know how uncertain the model is about its prediction.\n",
    "\n",
    "## What is Monte Carlo Dropout?\n",
    "\n",
    "**Monte Carlo Dropout (MC Dropout)** is a technique used to estimate **epistemic uncertainty** in deep learning models. Dropout is traditionally used as a regularization technique to prevent overfitting during training by randomly \"dropping out\" neurons in the network. However, **in MC Dropout, Dropout is also applied during inference** to get different predictions each time we pass the input through the network.\n",
    "\n",
    "This allows us to collect multiple outputs (by running the same input through the model multiple times), which can be used to calculate the model's **mean prediction** and **uncertainty** (standard deviation) of those predictions.\n",
    "\n",
    "### Steps to Apply MC Dropout:\n",
    "\n",
    "1. **Activate Dropout during inference**: Normally, Dropout is only used during training. In MC Dropout, we turn it on during inference as well.\n",
    "  \n",
    "2. **Perform multiple forward passes**: Run the input through the model multiple times (e.g., 100 iterations), each time with Dropout applied. This will give us different outputs because different neurons will be dropped each time.\n",
    "  \n",
    "3. **Estimate mean and uncertainty**: Calculate the mean of these predictions to get the final output. The standard deviation of these predictions gives us the uncertainty.\n",
    "\n",
    "## Why is MC Dropout Useful?\n",
    "\n",
    "- **Uncertainty Quantification**: MC Dropout helps us estimate the uncertainty of the model's predictions. This is especially useful in critical tasks such as healthcare or autonomous vehicles.\n",
    "- **Easy to Implement**: MC Dropout is relatively easy to implement in existing models since it only requires modifying how Dropout is applied during inference.\n",
    "- **Improved Decision-Making**: By knowing how uncertain a model is, we can make better decisions. For example, if a model is highly uncertain about a medical diagnosis, it can alert a human expert to take a closer look.\n",
    "\n",
    "\n",
    "## Python Code Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f0e9c846",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): Identity()\n",
      "  (layer1): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Sequential(\n",
      "    (0): Dropout(p=0.5, inplace=False)\n",
      "    (1): Linear(in_features=2048, out_features=100, bias=True)\n",
      "  )\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "def init_model():\n",
    "    model = models.wide_resnet50_2(pretrained=True)\n",
    "    model.conv1 = nn.Conv2d(model.conv1.in_channels, \n",
    "                            model.conv1.out_channels,\n",
    "                            3, 1, 1)  # Change kernel size to 3x3 with padding 1\n",
    "    model.maxpool = nn.Identity()  # Remove the maxpooling layer\n",
    "    model.dropout = nn.Dropout(p=0.5)  # Add dropout with 50% probability\n",
    "    # Change the final fully connected layer to fit CIFAR-100 classes\n",
    "    model.fc = nn.Sequential(\n",
    "        nn.Dropout(p=0.5),  # Add another Dropout before the final layer\n",
    "        nn.Linear(model.fc.in_features, 100)\n",
    "    )\n",
    "    return model\n",
    "\n",
    "model = init_model()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0518fea",
   "metadata": {},
   "source": [
    "### MC Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f1de2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def enable_dropout(model):\n",
    "    \"\"\" Enable dropout layers during inference \"\"\"\n",
    "    for m in model.modules():\n",
    "        if isinstance(m, nn.Dropout):\n",
    "            m.train()\n",
    "\n",
    "            \n",
    "def mc_dropout_predict(model, x, n_iter=50):\n",
    "    \"\"\" Perform MC Dropout for uncertainty estimation \"\"\"\n",
    "    model.eval()\n",
    "    enable_dropout(model)\n",
    "    \n",
    "    predictions = []\n",
    "    for _ in range(n_iter):\n",
    "        with torch.no_grad():\n",
    "            pred = model(x)\n",
    "            predictions.append(pred)\n",
    "    \n",
    "    predictions = torch.stack(predictions)\n",
    "    mean_prediction = predictions.mean(dim=0)\n",
    "    uncertainty = predictions.std(dim=0)\n",
    "    \n",
    "    return mean_prediction, uncertainty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ac57036",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cifar100(batch_size=1):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((32, 32)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761)),\n",
    "    ])\n",
    "    \n",
    "    # Load CIFAR-100 training set\n",
    "    dataset = datasets.CIFAR100(root='./data', train=False, download=True, transform=transform)\n",
    "    \n",
    "    # Randomly select a few images\n",
    "    random_indices = random.sample(range(len(dataset)), 10)  # Select 10 random images\n",
    "    subset = Subset(dataset, random_indices)\n",
    "    \n",
    "    data_loader = DataLoader(subset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    return data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd993692",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Mean Prediction (First 5 classes):  tensor([ 0.1195,  0.4123, -1.5641,  0.3386, -0.0486], device='cuda:0')\n",
      "Uncertainty (First 5 classes):  tensor([0.3807, 0.4994, 0.4753, 0.4732, 0.5316], device='cuda:0')\n",
      "Mean Prediction (First 5 classes):  tensor([-0.1361,  0.1523, -0.4898,  0.1995, -0.2344], device='cuda:0')\n",
      "Uncertainty (First 5 classes):  tensor([0.3003, 0.3387, 0.3496, 0.2998, 0.3705], device='cuda:0')\n",
      "Mean Prediction (First 5 classes):  tensor([-0.3431,  0.4221, -1.0592,  0.1948, -0.4164], device='cuda:0')\n",
      "Uncertainty (First 5 classes):  tensor([0.4319, 0.5049, 0.5084, 0.5179, 0.5629], device='cuda:0')\n",
      "Mean Prediction (First 5 classes):  tensor([-0.5336, -0.2419, -0.8448,  0.3664, -0.5599], device='cuda:0')\n",
      "Uncertainty (First 5 classes):  tensor([0.4038, 0.4211, 0.3976, 0.4447, 0.3795], device='cuda:0')\n",
      "Mean Prediction (First 5 classes):  tensor([-0.2060, -0.1346, -1.1554,  0.1303, -0.6362], device='cuda:0')\n",
      "Uncertainty (First 5 classes):  tensor([0.4847, 0.5008, 0.5198, 0.4362, 0.5498], device='cuda:0')\n",
      "Mean Prediction (First 5 classes):  tensor([-0.1128,  0.3082, -1.3535,  0.3987, -0.0572], device='cuda:0')\n",
      "Uncertainty (First 5 classes):  tensor([0.3974, 0.4651, 0.4065, 0.4049, 0.4325], device='cuda:0')\n",
      "Mean Prediction (First 5 classes):  tensor([ 0.0339,  0.2457, -1.1979,  0.2971, -0.1890], device='cuda:0')\n",
      "Uncertainty (First 5 classes):  tensor([0.5315, 0.4667, 0.4591, 0.3775, 0.4648], device='cuda:0')\n",
      "Mean Prediction (First 5 classes):  tensor([-0.4253,  0.1618, -1.3990, -0.1079, -0.4659], device='cuda:0')\n",
      "Uncertainty (First 5 classes):  tensor([0.4069, 0.3309, 0.3437, 0.4033, 0.5331], device='cuda:0')\n",
      "Mean Prediction (First 5 classes):  tensor([-0.3177,  0.5055, -1.6169,  0.5591, -0.7041], device='cuda:0')\n",
      "Uncertainty (First 5 classes):  tensor([0.5870, 0.4941, 0.6024, 0.5231, 0.5581], device='cuda:0')\n",
      "Mean Prediction (First 5 classes):  tensor([-0.0249,  0.2403, -1.1682,  0.2515, -0.6028], device='cuda:0')\n",
      "Uncertainty (First 5 classes):  tensor([0.4599, 0.5193, 0.3651, 0.4835, 0.5728], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "cifar100_loader = load_cifar100(batch_size=1)\n",
    "model = model.cuda()  # Use GPU if available\n",
    "for inputs, labels in cifar100_loader:\n",
    "    inputs = inputs.cuda()  # Move inputs to GPU\n",
    "        \n",
    "    # Perform MC Dropout and get mean prediction and uncertainty\n",
    "    mean_pred, uncertainty = mc_dropout_predict(model, inputs, n_iter=50)\n",
    "        \n",
    "    print(\"Mean Prediction (First 5 classes): \", mean_pred[0][:5])\n",
    "    print(\"Uncertainty (First 5 classes): \", uncertainty[0][:5])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ldl",
   "language": "python",
   "name": "ldl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
